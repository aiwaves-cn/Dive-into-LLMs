{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dc9af59-0db6-433c-8cb2-63b1f684eae3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 动手实战大模型: Lecture 1\n",
    "# OpenAI GPT API 使用\n",
    "\n",
    "\n",
    "## Basics\n",
    "#### Set system proxy for calling OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daa78562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/chunshu/miniforge3/lib/python3.10/site-packages (1.13.3)\n",
      "Collecting openai\n",
      "  Downloading openai-1.14.0-py3-none-any.whl (257 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.5/257.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /Users/chunshu/miniforge3/lib/python3.10/site-packages (from openai) (3.6.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/chunshu/miniforge3/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/chunshu/miniforge3/lib/python3.10/site-packages (from openai) (0.24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/chunshu/miniforge3/lib/python3.10/site-packages (from openai) (1.10.7)\n",
      "Requirement already satisfied: sniffio in /Users/chunshu/miniforge3/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/chunshu/miniforge3/lib/python3.10/site-packages (from openai) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/chunshu/miniforge3/lib/python3.10/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/chunshu/miniforge3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.1)\n",
      "Requirement already satisfied: certifi in /Users/chunshu/miniforge3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /Users/chunshu/miniforge3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (0.16.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/chunshu/miniforge3/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.13.3\n",
      "    Uninstalling openai-1.13.3:\n",
      "      Successfully uninstalled openai-1.13.3\n",
      "Successfully installed openai-1.14.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01def669-0b7d-4c35-9283-a7f5a80011db",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export https_proxy=http://127.0.0.1:7890 http_proxy=http://127.0.0.1:7890 all_proxy=socks5://127.0.0.1:7890"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69364556-d8e1-4117-a6bd-1d8f381b248f",
   "metadata": {},
   "source": [
    "#### Load OpenAI Python libaries & api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdb7cc8b-0098-4d56-9a64-23b8a42f6f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf7dc48-edf2-4103-b2d4-d6b5065dae0a",
   "metadata": {},
   "source": [
    "#### Load api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04957a63-e010-4d70-ae40-7bf79758fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = open(\"api.key\").read() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7985964f-f448-4aea-b7fa-5ca856c286e8",
   "metadata": {},
   "source": [
    "#### Define client for OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bcae395-685e-4c72-bf46-55cc127c2655",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6fec7c-5240-4b79-b738-ef19e277e54e",
   "metadata": {},
   "source": [
    "#### Select the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e1cfd25-44e3-4928-8a43-811a6c3805b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-3.5-turbo-0125\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc19659-d663-4319-85cf-f4ff8406578c",
   "metadata": {},
   "source": [
    "#### Write the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e11449a4-47f2-4217-b699-3aa8de5faeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"鲁迅为什么暴打周树人。\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36cea94-67bf-4095-b721-9d9396a2b7c4",
   "metadata": {},
   "source": [
    "#### Assemble the request message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "676e4bb3-1df7-417e-be6f-2a1c227ea241",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": prompt,\n",
    "    },\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5835e2ea-76b5-4042-9e27-4d0e55c28348",
   "metadata": {},
   "source": [
    "#### Send the request to OpenAI and get the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba8330c9-ba80-4f75-9dc6-85573c4753f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "            model=model, messages=messages, temperature=1, top_p=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d05852-45ce-4556-aa5b-6e6a90f798b9",
   "metadata": {},
   "source": [
    "#### Response Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18dfedf7-69d2-43bd-810e-44c614e77056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-92vHpfFj7xFJPay0sWyw7GLvgpCRT\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"\\u9c81\\u8fc5\\u66b4\\u6253\\u5468\\u6811\\u4eba\\u662f\\u56e0\\u4e3a\\u5468\\u6811\\u4eba\\u5728\\u4ed6\\u7684\\u4f5c\\u54c1\\u300a\\u51b0\\u5fc3\\u81ea\\u4f20\\u300b\\u4e2d\\u5bf9\\u9c81\\u8fc5\\u8fdb\\u884c\\u4e86\\u4e25\\u5389\\u6279\\u8bc4\\uff0c\\u8ba4\\u4e3a\\u4ed6\\u662f\\u4e00\\u4e2a\\u5996\\u8273\\u7684\\u8bd7\\u4eba\\uff0c\\u6ca1\\u6709\\u5b9e\\u9645\\u7684\\u4f5c\\u54c1\\uff0c\\u53ea\\u4f1a\\u5199\\u8bbd\\u523a\\u6587\\u7ae0\\u3002\\u9c81\\u8fc5\\u5bf9\\u6b64\\u611f\\u5230\\u6124\\u6012\\uff0c\\u968f\\u540e\\u5728\\u4e00\\u6b21\\u89c1\\u9762\\u65f6\\u5bf9\\u5468\\u6811\\u4eba\\u8fdb\\u884c\\u4e86\\u66b4\\u529b\\u653b\\u51fb\\u3002\\u8fd9\\u4ef6\\u4e8b\\u4ef6\\u4e5f\\u6210\\u4e3a\\u4e86\\u6587\\u575b\\u4e0a\\u7684\\u4e00\\u4e2a\\u8f70\\u52a8\\u4e8b\\u4ef6\\uff0c\\u5f15\\u8d77\\u4e86\\u5e7f\\u6cdb\\u5173\\u6ce8\\u3002\",\n",
      "                \"role\": \"assistant\",\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1710483893,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"system_fingerprint\": \"fp_4f2ebda25a\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 144,\n",
      "        \"prompt_tokens\": 24,\n",
      "        \"total_tokens\": 168\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(json.loads(response.model_dump_json()), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e013ebe3-70aa-4932-bd6b-5424b534b9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'鲁迅暴打周树人是因为周树人在他的作品《冰心自传》中对鲁迅进行了严厉批评，认为他是一个妖艳的诗人，没有实际的作品，只会写讽刺文章。鲁迅对此感到愤怒，随后在一次见面时对周树人进行了暴力攻击。这件事件也成为了文坛上的一个轰动事件，引起了广泛关注。'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce3f687-92da-40f4-a9fb-11775ef259b3",
   "metadata": {},
   "source": [
    "#### Cost for API usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d797bf4-94cf-4c7c-bd06-5f79365a2f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=17, prompt_tokens=9, total_tokens=26)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0d5924e-80e1-4d39-bff7-3fd8c334811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = 0.01 * response.usage.prompt_tokens / 1000 + 0.03 * response.usage.completion_tokens / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e1ad716-e6f8-4a19-aed7-82c5c5ad1d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006100000000000001"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7748a21-47d5-4416-8dd0-ddf59d5719de",
   "metadata": {},
   "source": [
    "#### Change the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f809dfa6-d3c3-4f49-a556-69443a7574f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "鲁迅暴打周树人这一表述存在误解。事实上，鲁迅与周树人是同一个人，鲁迅是周树人的笔名。周树人是鲁迅的本名，而鲁迅是他在文学和其他领域的创作中使用的笔名之一。鲁迅（1881年9月25日－1936年10月19日）是中国现代文学的奠基人之一，他在小说、杂文、翻译、文学批评等方面均有深远影响。因此，说“鲁迅暴打周树人”并不准确，这种说法可能源于对鲁迅和周树人关系的误解或是出于玩笑。\n"
     ]
    }
   ],
   "source": [
    "model = \"gpt-4-turbo-preview\"\n",
    "\n",
    "messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"鲁迅为什么暴打周树人。\"\n",
    "    },\n",
    "  ]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "            model=model, messages=messages, n=1, top_p=0.9, temperature=1)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067c5cc9-5eed-499f-898d-33511f1dec77",
   "metadata": {},
   "source": [
    "## Advanced Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e812985f-b9f8-4198-aaa3-4f5cc5b1c1a2",
   "metadata": {},
   "source": [
    "### Request parameters\n",
    "\n",
    "A chat completion API call parameters,\n",
    "**Required**\n",
    "- `model`: the name of the model you want to use (e.g., `gpt-3.5-turbo`, `gpt-4`, `gpt-3.5-turbo-16k-1106`)\n",
    "- `messages`: a list of message objects, where each object has two required fields:\n",
    "    - `role`: the role of the messenger (either `system`, `user`, or `assistant`)\n",
    "    - `content`: the content of the message (e.g., `Write me a beautiful poem`)\n",
    "\n",
    "Messages can also contain an optional `name` field, which give the messenger a name. E.g., `example-user`, `Alice`, `BlackbeardBot`. Names may not contain spaces.\n",
    "\n",
    "**Optional**\n",
    "- `frequency_penalty`: Penalizes tokens based on their frequency, reducing repetition.\n",
    "- `logit_bias`: Modifies likelihood of specified tokens with bias values.\n",
    "- `logprobs`: Returns log probabilities of output tokens if true.\n",
    "- `top_logprobs`: Specifies the number of most likely tokens to return at each position.\n",
    "- `max_tokens`: Sets the maximum number of generated tokens in chat completion.\n",
    "- `n`: Generates a specified number of chat completion choices for each input.\n",
    "- `presence_penalty`: Penalizes new tokens based on their presence in the text.\n",
    "- `response_format`: Specifies the output format, e.g., JSON mode.\n",
    "- `seed`: Ensures deterministic sampling with a specified seed.\n",
    "- `stop`: Specifies up to 4 sequences where the API should stop generating tokens.\n",
    "- `stream`: Sends partial message deltas as tokens become available.\n",
    "- `temperature`: Sets the sampling temperature between 0 and 2.\n",
    "- `top_p`: Uses nucleus sampling; considers tokens with top_p probability mass.\n",
    "- `tools`: Lists functions the model may call.\n",
    "- `tool_choice`: Controls the model's function calls (none/auto/function).\n",
    "- `user`: Unique identifier for end-user monitoring and abuse detection.\n",
    "\n",
    "\n",
    "As of January 2024, you can also optionally submit a list of `functions` that tell GPT whether it can generate JSON to feed into a function. For details, see the [documentation](https://platform.openai.com/docs/guides/function-calling), [API reference](https://platform.openai.com/docs/api-reference/chat), or the Cookbook guide [How to call functions with chat models](How_to_call_functions_with_chat_models.ipynb).\n",
    "\n",
    "Typically, a conversation will start with a system message that tells the assistant how to behave, followed by alternating user and assistant messages, but you are not required to follow this format.\n",
    "\n",
    "Let's look at an example chat API calls to see how the chat format works in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "100033ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example OpenAI Python library request\n",
    "MODEL = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"帮我写一段代码，实现一个简单的计算器。\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"计算器都要包括什么功能?\"},\n",
    "        {\"role\": \"user\", \"content\": \"加减乘除都要包括。\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    "    logprobs=False,\n",
    "    top_p=0.9,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af8813d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-92Eem4chIKwj3z53Z1FjiYz8VJ4uU\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"\\u597d\\u7684\\uff0c\\u4ee5\\u4e0b\\u662f\\u4e00\\u4e2a\\u7b80\\u5355\\u7684\\u8ba1\\u7b97\\u5668\\u4ee3\\u7801\\u793a\\u4f8b\\uff0c\\u53ef\\u4ee5\\u5b9e\\u73b0\\u52a0\\u51cf\\u4e58\\u9664\\u529f\\u80fd\\uff1a\\n\\n```python\\ndef add(x, y):\\n    return x + y\\n\\ndef subtract(x, y):\\n    return x - y\\n\\ndef multiply(x, y):\\n    return x * y\\n\\ndef divide(x, y):\\n    if y == 0:\\n        return \\\"Error: Division by zero!\\\"\\n    return x / y\\n\\nprint(\\\"\\u9009\\u62e9\\u64cd\\u4f5c\\uff1a\\\")\\nprint(\\\"1. \\u76f8\\u52a0\\\")\\nprint(\\\"2. \\u76f8\\u51cf\\\")\\nprint(\\\"3. \\u76f8\\u4e58\\\")\\nprint(\\\"4. \\u76f8\\u9664\\\")\\n\\nchoice = input(\\\"\\u8f93\\u5165\\u9009\\u62e9(1/2/3/4): \\\")\\n\\nnum1 = float(input(\\\"\\u8f93\\u5165\\u7b2c\\u4e00\\u4e2a\\u6570\\u5b57: \\\"))\\nnum2 = float(input(\\\"\\u8f93\\u5165\\u7b2c\\u4e8c\\u4e2a\\u6570\\u5b57: \\\"))\\n\\nif choice == '1':\\n    print(\\\"\\u7ed3\\u679c: \\\", add(num1, num2))\\nelif choice == '2':\\n    print(\\\"\\u7ed3\\u679c: \\\", subtract(num1, num2))\\nelif choice == '3':\\n    print(\\\"\\u7ed3\\u679c: \\\", multiply(num1, num2))\\nelif choice == '4':\\n    print(\\\"\\u7ed3\\u679c: \\\", divide(num1, num2))\\nelse:\\n    print(\\\"\\u65e0\\u6548\\u7684\\u8f93\\u5165\\\")\\n```\\n\\n\\u4f60\\u53ef\\u4ee5\\u8fd0\\u884c\\u8fd9\\u6bb5\\u4ee3\\u7801\\uff0c\\u6839\\u636e\\u63d0\\u793a\\u8f93\\u5165\\u6570\\u5b57\\u548c\\u64cd\\u4f5c\\u9009\\u62e9\\uff0c\\u5373\\u53ef\\u8fdb\\u884c\\u52a0\\u51cf\\u4e58\\u9664\\u8ba1\\u7b97\\u3002\",\n",
      "                \"role\": \"assistant\",\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1710320024,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"system_fingerprint\": \"fp_4f0b692a78\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 294,\n",
      "        \"prompt_tokens\": 68,\n",
      "        \"total_tokens\": 362\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(json.loads(response.model_dump_json()), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0bc7b5",
   "metadata": {},
   "source": [
    "As you can see, the response object has a few fields:\n",
    "- `id`: the ID of the request\n",
    "- `choices`: a list of completion objects (only one, unless you set `n` greater than 1)\n",
    "    - `finish_reason`: the reason the model stopped generating text (either `stop`, or `length` if `max_tokens` limit was reached)\n",
    "    - `index`: The index of the choice in the list of choices.\n",
    "    - `logprobs`: Log probability information for the choice.\n",
    "    - `message`: the message object generated by the model\n",
    "        - `content`: content of message\n",
    "        - `role`: The role of the author of this message.\n",
    "        - `tool_calls`: The tool calls generated by the model, such as function calls. if the tools is given\n",
    "- `created`: the timestamp of the request\n",
    "- `model`: the full name of the model used to generate the response\n",
    "- `object`: the type of object returned (e.g., `chat.completion`)\n",
    "- `system_fingerprint`: This fingerprint represents the backend configuration that the model runs with.\n",
    "- `usage`: the number of tokens used to generate the replies, counting prompt, completion, and total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee21a8b9",
   "metadata": {},
   "source": [
    "Extract just the reply with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9121e0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好的，以下是一个简单的计算器代码示例，可以实现加减乘除功能：\n",
      "\n",
      "```python\n",
      "def add(x, y):\n",
      "    return x + y\n",
      "\n",
      "def subtract(x, y):\n",
      "    return x - y\n",
      "\n",
      "def multiply(x, y):\n",
      "    return x * y\n",
      "\n",
      "def divide(x, y):\n",
      "    if y == 0:\n",
      "        return \"Error: Division by zero!\"\n",
      "    return x / y\n",
      "\n",
      "print(\"选择操作：\")\n",
      "print(\"1. 相加\")\n",
      "print(\"2. 相减\")\n",
      "print(\"3. 相乘\")\n",
      "print(\"4. 相除\")\n",
      "\n",
      "choice = input(\"输入选择(1/2/3/4): \")\n",
      "\n",
      "num1 = float(input(\"输入第一个数字: \"))\n",
      "num2 = float(input(\"输入第二个数字: \"))\n",
      "\n",
      "if choice == '1':\n",
      "    print(\"结果: \", add(num1, num2))\n",
      "elif choice == '2':\n",
      "    print(\"结果: \", subtract(num1, num2))\n",
      "elif choice == '3':\n",
      "    print(\"结果: \", multiply(num1, num2))\n",
      "elif choice == '4':\n",
      "    print(\"结果: \", divide(num1, num2))\n",
      "else:\n",
      "    print(\"无效的输入\")\n",
      "```\n",
      "\n",
      "你可以运行这段代码，根据提示输入数字和操作选择，即可进行加减乘除计算。\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0972bd",
   "metadata": {},
   "source": [
    "### How to stream completions\n",
    "\n",
    "By default, when you request a completion from the OpenAI, the entire completion is generated before being sent back in a single response.\n",
    "\n",
    "If you're generating long completions, waiting for the response can take many seconds.\n",
    "\n",
    "To get responses sooner, you can 'stream' the completion as it's being generated. This allows you to start printing or processing the beginning of the completion before the full completion is finished.\n",
    "\n",
    "To stream completions, set `stream=True` when calling the chat completions or completions endpoints. This will return an object that streams back the response as [data-only server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#event_stream_format). Extract chunks from the `delta` field rather than the `message` field.\n",
    "\n",
    "#### Downsides\n",
    "\n",
    "Note that using `stream=True` in a production application makes it more difficult to moderate the content of the completions, as partial completions may be more difficult to evaluate. This may have implications for [approved usage](https://beta.openai.com/docs/usage-guidelines).\n",
    "\n",
    "Another small drawback of streaming responses is that the response no longer includes the `usage` field to tell you how many tokens were consumed. After receiving and combining all of the responses, you can calculate this yourself using [`tiktoken`](How_to_count_tokens_with_tiktoken.ipynb).\n",
    "\n",
    "#### Example code\n",
    "\n",
    "Below, this section shows:\n",
    "1. What a typical chat completion response looks like\n",
    "2. What a streaming chat completion response looks like\n",
    "3. How much time is saved by streaming a chat completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779a2325",
   "metadata": {},
   "source": [
    "#### 1. What a typical chat completion response looks like\n",
    "\n",
    "With a typical ChatCompletions API call, the response is first computed and then returned all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f405266f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full response received 4.60 seconds after request\n",
      "Full response received:\n",
      "ChatCompletion(id='chatcmpl-92EufBAdI8WLTMRYBlicJxxjhorlp', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='生活中总会遇到各种各样的困难和挑战，但是我们不能因此放弃，而是要勇敢面对。正如一句古语所说：“困难像弹簧，你弱它就强，你强它就弱。”只有坚持不懈，勇敢面对困难，才能最终战胜困难，取得成功。在人生的道路上，我们要学会坚强，学会勇敢，学会不断进取，只有这样，我们才能走得更远，看到更美好的风景。让我们一起努力，迎接生活的挑战，创造属于自己的精彩人生！', role='assistant', function_call=None, tool_calls=None))], created=1710321009, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_4f0b692a78', usage=CompletionUsage(completion_tokens=219, prompt_tokens=18, total_tokens=237))\n"
     ]
    }
   ],
   "source": [
    "# record the time before the request is sent\n",
    "start_time = time.time()\n",
    "\n",
    "# send a ChatCompletion request to count to 100\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': '给我写一个100字的小作文.'}\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "# calculate the time it took to receive the response\n",
    "response_time = time.time() - start_time\n",
    "\n",
    "# print the time delay and text received\n",
    "print(f\"Full response received {response_time:.2f} seconds after request\")\n",
    "print(f\"Full response received:\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72fd2e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content: \n",
      "生活中总会遇到各种各样的困难和挑战，但是我们不能因此放弃，而是要勇敢面对。正如一句古语所说：“困难像弹簧，你弱它就强，你强它就弱。”只有坚持不懈，勇敢面对困难，才能最终战胜困难，取得成功。在人生的道路上，我们要学会坚强，学会勇敢，学会不断进取，只有这样，我们才能走得更远，看到更美好的风景。让我们一起努力，迎接生活的挑战，创造属于自己的精彩人生！\n"
     ]
    }
   ],
   "source": [
    "reply_content = response.choices[0].message.content\n",
    "print(f\"Extracted content: \\n{reply_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa1050b",
   "metadata": {},
   "source": [
    "#### 2. How to stream a chat completion\n",
    "\n",
    "With a streaming API call, the response is sent back incrementally in chunks via an [event stream](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#event_stream_format). In Python, you can iterate over these events with a `for` loop.\n",
    "\n",
    "Let's see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12b9787f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='生', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "生\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='活', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "活\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='中', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "中\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='总', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "总\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='会', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "会\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='遇', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "遇\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='到', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "到\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='各', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "各\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='种', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "种\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='各', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "各\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='样', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "样\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='的', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "的\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='困', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "困\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='难', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "难\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='和', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "和\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='挑', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "挑\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='战', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "战\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='，', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "，\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='但', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "但\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='是', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "是\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='我们', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "我们\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='不能', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "不能\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='因', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "因\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='此', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "此\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='放', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "放\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='弃', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "弃\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='，', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "，\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='而', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "而\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='是', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "是\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='要', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "要\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='勇', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "勇\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='敢', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "敢\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='面', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "面\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='对', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "对\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='。', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "。\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='正', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "正\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='如', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "如\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='一', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "一\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='句', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "句\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='古', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "古\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='语', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "语\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='所', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "所\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='说', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "说\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='：“', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "：“\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='困', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "困\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='难', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "难\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='像', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "像\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='弹', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "弹\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='簧', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "簧\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='，', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "，\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='你', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "你\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='弱', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "弱\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='它', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "它\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='就', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "就\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='强', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "强\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='，', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "，\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='你', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "你\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='强', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "强\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='它', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "它\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='就', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "就\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='弱', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "弱\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='。”', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "。”\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='只', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "只\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='有', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "有\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='不', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "不\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='断', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "断\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='努', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "努\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='力', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "力\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='，', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "，\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='坚', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "坚\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='持', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "持\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='不', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "不\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='懈', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "懈\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='，', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "，\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='才', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "才\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='能', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "能\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='克', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "克\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='服', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "服\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='困', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "困\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='难', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "难\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='，', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "，\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='取', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "取\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='得', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "得\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='成功', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "成功\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='。', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "。\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='在', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "在\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='人', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "人\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='生', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "生\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='的', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "的\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='道', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "道\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='路', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "路\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='上', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "上\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='，', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "，\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='我们', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "我们\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='要', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "要\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='学', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "学\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='会', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "会\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='坚', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "坚\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='强', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "强\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='，', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "，\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='学', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "学\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='会', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "会\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='勇', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "勇\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='敢', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "敢\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='，', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "，\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='学', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "学\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='会', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "会\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='面', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "面\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='对', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "对\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='挑', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "挑\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='战', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "战\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='。', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "。\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='只', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "只\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='有', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "有\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='这', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "这\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='样', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "样\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='，', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "，\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='我们', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "我们\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='才', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "才\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='能', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "能\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='不', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "不\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='断', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "断\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='成', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "成\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='长', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "长\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='，', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "，\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='不', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "不\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='断', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "断\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='进', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "进\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='步', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "步\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='，', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "，\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='让', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "让\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='自', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "自\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='己', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "己\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='变', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "变\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='得', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "得\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='更', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "更\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='加', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "加\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='强', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "强\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='大', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "大\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='。', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "。\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='让', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "让\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='我们', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "我们\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='一', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "一\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='起', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "起\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='勇', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "勇\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='敢', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "敢\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='面', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "面\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='对', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "对\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='生', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "生\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='活', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "活\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='中', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "中\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='的', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "的\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='困', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "困\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='难', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "难\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='，', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "，\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='迎', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "迎\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='接', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "接\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='更', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "更\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='美', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "美\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='好', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "好\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='的', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "的\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='明', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "明\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='天', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "天\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content='。', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "。\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-92F22Ge3uZYvffGMoVxleOaJ7OCzP', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None)], created=1710321466, model='gpt-3.5-turbo-0125', object='chat.completion.chunk', system_fingerprint='fp_4f0b692a78')\n",
      "None\n",
      "****************\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo-0125',\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': \"给我写一个100字的小作文.\"}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    stream=True  # this time, we set stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk)\n",
    "    print(chunk.choices[0].delta.content)\n",
    "    print(\"****************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c3eaac",
   "metadata": {},
   "source": [
    "As you can see above, streaming responses have a `delta` field rather than a `message` field. `delta` can hold things like:\n",
    "- a role token (e.g., `{\"role\": \"assistant\"}`)\n",
    "- a content token (e.g., `{\"content\": \"\\n\\n\"}`)\n",
    "- nothing (e.g., `{}`), when the stream is over"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2743a432",
   "metadata": {},
   "source": [
    "#### 3. How much time is saved by streaming a chat completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "658a5774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message received 0.76 seconds after request: \n",
      "Message received 0.78 seconds after request: 生\n",
      "Message received 0.78 seconds after request: 活\n",
      "Message received 0.82 seconds after request: 中\n",
      "Message received 0.82 seconds after request: 总\n",
      "Message received 0.89 seconds after request: 会\n",
      "Message received 0.89 seconds after request: 遇\n",
      "Message received 0.97 seconds after request: 到\n",
      "Message received 0.97 seconds after request: 各\n",
      "Message received 1.05 seconds after request: 种\n",
      "Message received 1.05 seconds after request: 各\n",
      "Message received 1.11 seconds after request: 样\n",
      "Message received 1.11 seconds after request: 的\n",
      "Message received 1.18 seconds after request: 困\n",
      "Message received 1.19 seconds after request: 难\n",
      "Message received 1.23 seconds after request: 和\n",
      "Message received 1.23 seconds after request: 挑\n",
      "Message received 1.28 seconds after request: 战\n",
      "Message received 1.28 seconds after request: ，\n",
      "Message received 1.31 seconds after request: 但\n",
      "Message received 1.31 seconds after request: 是\n",
      "Message received 1.36 seconds after request: 我们\n",
      "Message received 1.36 seconds after request: 不能\n",
      "Message received 1.44 seconds after request: 因\n",
      "Message received 1.44 seconds after request: 此\n",
      "Message received 1.53 seconds after request: 放\n",
      "Message received 1.53 seconds after request: 弃\n",
      "Message received 1.54 seconds after request: ，\n",
      "Message received 1.54 seconds after request: 而\n",
      "Message received 1.61 seconds after request: 是\n",
      "Message received 1.61 seconds after request: 要\n",
      "Message received 1.68 seconds after request: 勇\n",
      "Message received 1.68 seconds after request: 敢\n",
      "Message received 1.74 seconds after request: 面\n",
      "Message received 1.74 seconds after request: 对\n",
      "Message received 1.76 seconds after request: 。\n",
      "Message received 1.76 seconds after request: 只\n",
      "Message received 1.83 seconds after request: 有\n",
      "Message received 1.83 seconds after request: 经\n",
      "Message received 1.89 seconds after request: 历\n",
      "Message received 1.89 seconds after request: 过\n",
      "Message received 1.94 seconds after request: 风\n",
      "Message received 1.94 seconds after request: 雨\n",
      "Message received 2.00 seconds after request: 的\n",
      "Message received 2.00 seconds after request: 洗\n",
      "Message received 2.04 seconds after request: 礼\n",
      "Message received 2.04 seconds after request: ，\n",
      "Message received 2.11 seconds after request: 我们\n",
      "Message received 2.11 seconds after request: 才\n",
      "Message received 2.11 seconds after request: 能\n",
      "Message received 2.11 seconds after request: 变\n",
      "Message received 2.18 seconds after request: 得\n",
      "Message received 2.18 seconds after request: 更\n",
      "Message received 2.23 seconds after request: 加\n",
      "Message received 2.23 seconds after request: 坚\n",
      "Message received 2.31 seconds after request: 强\n",
      "Message received 2.31 seconds after request: 和\n",
      "Message received 2.35 seconds after request: 成\n",
      "Message received 2.35 seconds after request: 熟\n",
      "Message received 2.39 seconds after request: 。\n",
      "Message received 2.39 seconds after request: 在\n",
      "Message received 2.42 seconds after request: 人\n",
      "Message received 2.42 seconds after request: 生\n",
      "Message received 2.45 seconds after request: 的\n",
      "Message received 2.45 seconds after request: 道\n",
      "Message received 2.50 seconds after request: 路\n",
      "Message received 2.50 seconds after request: 上\n",
      "Message received 2.54 seconds after request: ，\n",
      "Message received 2.54 seconds after request: 我们\n",
      "Message received 2.60 seconds after request: 要\n",
      "Message received 2.60 seconds after request: 学\n",
      "Message received 2.66 seconds after request: 会\n",
      "Message received 2.66 seconds after request: 坚\n",
      "Message received 2.72 seconds after request: 持\n",
      "Message received 2.72 seconds after request: 和\n",
      "Message received 2.79 seconds after request: 努\n",
      "Message received 2.79 seconds after request: 力\n",
      "Message received 2.81 seconds after request: ，\n",
      "Message received 2.81 seconds after request: 不\n",
      "Message received 2.85 seconds after request: 断\n",
      "Message received 2.85 seconds after request: 提\n",
      "Message received 2.91 seconds after request: 升\n",
      "Message received 2.91 seconds after request: 自\n",
      "Message received 2.98 seconds after request: 己\n",
      "Message received 2.98 seconds after request: 的\n",
      "Message received 3.03 seconds after request: 能\n",
      "Message received 3.03 seconds after request: 力\n",
      "Message received 3.11 seconds after request: 和\n",
      "Message received 3.11 seconds after request: 素\n",
      "Message received 3.17 seconds after request: 质\n",
      "Message received 3.17 seconds after request: 。\n",
      "Message received 3.22 seconds after request: 无\n",
      "Message received 3.22 seconds after request: 论\n",
      "Message received 3.28 seconds after request: 遇\n",
      "Message received 3.28 seconds after request: 到\n",
      "Message received 3.40 seconds after request: 什\n",
      "Message received 3.40 seconds after request: 么\n",
      "Message received 3.43 seconds after request: 困\n",
      "Message received 3.43 seconds after request: 难\n",
      "Message received 3.47 seconds after request: ，\n",
      "Message received 3.47 seconds after request: 我们\n",
      "Message received 3.52 seconds after request: 都\n",
      "Message received 3.52 seconds after request: 要\n",
      "Message received 3.59 seconds after request: 保\n",
      "Message received 3.59 seconds after request: 持\n",
      "Message received 3.62 seconds after request: 乐\n",
      "Message received 3.62 seconds after request: 观\n",
      "Message received 3.69 seconds after request: 的\n",
      "Message received 3.69 seconds after request: 心\n",
      "Message received 3.75 seconds after request: 态\n",
      "Message received 3.75 seconds after request: ，\n",
      "Message received 3.79 seconds after request: 相\n",
      "Message received 3.79 seconds after request: 信\n",
      "Message received 3.83 seconds after request: 自\n",
      "Message received 3.83 seconds after request: 己\n",
      "Message received 3.87 seconds after request: 一\n",
      "Message received 3.87 seconds after request: 定\n",
      "Message received 3.97 seconds after request: 能\n",
      "Message received 3.97 seconds after request: 够\n",
      "Message received 4.11 seconds after request: 克\n",
      "Message received 4.11 seconds after request: 服\n",
      "Message received 4.11 seconds after request: 一\n",
      "Message received 4.11 seconds after request: 切\n",
      "Message received 4.18 seconds after request: 困\n",
      "Message received 4.18 seconds after request: 难\n",
      "Message received 4.20 seconds after request: ，\n",
      "Message received 4.20 seconds after request: 迎\n",
      "Message received 4.25 seconds after request: 接\n",
      "Message received 4.25 seconds after request: 更\n",
      "Message received 4.28 seconds after request: 美\n",
      "Message received 4.28 seconds after request: 好\n",
      "Message received 4.37 seconds after request: 的\n",
      "Message received 4.37 seconds after request: 明\n",
      "Message received 4.42 seconds after request: 天\n",
      "Message received 4.42 seconds after request: 。\n",
      "Message received 4.44 seconds after request: 让\n",
      "Message received 4.44 seconds after request: 我们\n",
      "Message received 4.58 seconds after request: 一\n",
      "Message received 4.58 seconds after request: 起\n",
      "Message received 4.58 seconds after request: 努\n",
      "Message received 4.59 seconds after request: 力\n",
      "Message received 4.62 seconds after request: ，\n",
      "Message received 4.62 seconds after request: 创\n",
      "Message received 4.67 seconds after request: 造\n",
      "Message received 4.68 seconds after request: 属\n",
      "Message received 4.73 seconds after request: 于\n",
      "Message received 4.73 seconds after request: 自\n",
      "Message received 4.79 seconds after request: 己\n",
      "Message received 4.79 seconds after request: 的\n",
      "Message received 4.85 seconds after request: 精\n",
      "Message received 4.85 seconds after request: 彩\n",
      "Message received 4.88 seconds after request: 人\n",
      "Message received 4.88 seconds after request: 生\n",
      "Message received 4.88 seconds after request: ！\n",
      "Message received 4.88 seconds after request: None\n",
      "Full response received 4.88 seconds after request\n",
      "Full conversation received: 生活中总会遇到各种各样的困难和挑战，但是我们不能因此放弃，而是要勇敢面对。只有经历过风雨的洗礼，我们才能变得更加坚强和成熟。在人生的道路上，我们要学会坚持和努力，不断提升自己的能力和素质。无论遇到什么困难，我们都要保持乐观的心态，相信自己一定能够克服一切困难，迎接更美好的明天。让我们一起努力，创造属于自己的精彩人生！\n"
     ]
    }
   ],
   "source": [
    "# Example of an OpenAI ChatCompletion request with stream=True\n",
    "# https://platform.openai.com/docs/api-reference/streaming#chat/create-stream\n",
    "\n",
    "# record the time before the request is sent\n",
    "start_time = time.time()\n",
    "\n",
    "# send a ChatCompletion request to count to 100\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo-0125',\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': '给我写一个100字的小作文.'}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    stream=True  # again, we set stream=True\n",
    ")\n",
    "# create variables to collect the stream of chunks\n",
    "collected_chunks = []\n",
    "collected_messages = []\n",
    "# iterate through the stream of events\n",
    "for chunk in response:\n",
    "    chunk_time = time.time() - start_time  # calculate the time delay of the chunk\n",
    "    collected_chunks.append(chunk)  # save the event response\n",
    "    chunk_message = chunk.choices[0].delta.content  # extract the message\n",
    "    collected_messages.append(chunk_message)  # save the message\n",
    "    print(f\"Message received {chunk_time:.2f} seconds after request: {chunk_message}\")  # print the delay and text\n",
    "\n",
    "# print the time delay and text received\n",
    "print(f\"Full response received {chunk_time:.2f} seconds after request\")\n",
    "# clean None in collected_messages\n",
    "collected_messages = [m for m in collected_messages if m is not None]\n",
    "full_reply_content = ''.join([m for m in collected_messages])\n",
    "print(f\"Full conversation received: {full_reply_content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903f82b4",
   "metadata": {},
   "source": [
    "#### Time comparison\n",
    "\n",
    "In the example above, both requests took about 4 to 5 seconds to fully complete. Request times will vary depending on load and other stochastic factors.\n",
    "\n",
    "However, with the streaming request, we received the first token after 0.1 seconds, and subsequent tokens every ~0.01-0.02 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3306fa14",
   "metadata": {},
   "source": [
    "#### Count Tokens\n",
    "\n",
    "Streaming is a very helpful feature for latency-constrained applications such as Chatbots. However, with ```streaming=True```, you no longer have access to the ```usage``` field in the response. So it would be a bit tricky to accurately estimate the token consumption.\n",
    "\n",
    "Moreover, you may need to compute the number of tokens in the prompt and truncate the prompts that are too long for the model (e.g., `gpt-3.5-turbo-0125` has a context size of 16k while `gpt-4-turbo-preview` has a larger context size of 128k.) In these scenarios, it is helpful to be able to calculate the length of a message / response manually. \n",
    "\n",
    "In this section, we will show how to count token usage on your own with the ```tiktoken``` package.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5822db3",
   "metadata": {},
   "source": [
    "### How to count tokens with tiktoken\n",
    "\n",
    "[`tiktoken`](https://github.com/openai/tiktoken/blob/main/README.md) is a fast open-source tokenizer by OpenAI.\n",
    "\n",
    "Given a text string (e.g., `\"tiktoken is great!\"`) and an encoding (e.g., `\"cl100k_base\"`), a tokenizer can split the text string into a list of tokens (e.g., `[\"t\", \"ik\", \"token\", \" is\", \" great\", \"!\"]`).\n",
    "\n",
    "Splitting text strings into tokens is useful because GPT models see text in the form of tokens. Knowing how many tokens are in a text string can tell you (a) whether the string is too long for a text model to process and (b) how much an OpenAI API call costs (as usage is priced by token).\n",
    "\n",
    "\n",
    "\n",
    "#### How strings are typically tokenized\n",
    "\n",
    "In English, tokens commonly range in length from one character to one word (e.g., `\"t\"` or `\" great\"`), though in some languages tokens can be shorter than one character or longer than one word. Spaces are usually grouped with the starts of words (e.g., `\" is\"` instead of `\"is \"` or `\" \"`+`\"is\"`). You can quickly check how a string is tokenized at the [OpenAI Tokenizer](https://beta.openai.com/tokenizer), or the third-party [Tiktokenizer](https://tiktokenizer.vercel.app/) webapp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f331cd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /Users/chunshu/miniforge3/lib/python3.10/site-packages (0.3.3)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.6.0-cp310-cp310-macosx_11_0_arm64.whl (949 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.0/950.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /Users/chunshu/miniforge3/lib/python3.10/site-packages (from tiktoken) (2023.3.23)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/chunshu/miniforge3/lib/python3.10/site-packages (from tiktoken) (2.29.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/chunshu/miniforge3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/chunshu/miniforge3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/chunshu/miniforge3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/chunshu/miniforge3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "Installing collected packages: tiktoken\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.3.3\n",
      "    Uninstalling tiktoken-0.3.3:\n",
      "      Successfully uninstalled tiktoken-0.3.3\n",
      "Successfully installed tiktoken-0.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f43c0a",
   "metadata": {},
   "source": [
    "#### Load an encoding\n",
    "\n",
    "Use `tiktoken.get_encoding()` to load an encoding by name.\n",
    "\n",
    "The first time this runs, it will require an internet connection to download. Later runs won't need an internet connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "114ec364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fcc0d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e930e5",
   "metadata": {},
   "source": [
    "#### Turn text into tokens with `encoding.encode()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898e3033",
   "metadata": {},
   "source": [
    "The `.encode()` method converts a text string into a list of token integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2275d00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14888,\n",
       " 95,\n",
       " 83799,\n",
       " 45114,\n",
       " 118,\n",
       " 27327,\n",
       " 6701,\n",
       " 249,\n",
       " 80195,\n",
       " 35304,\n",
       " 2366,\n",
       " 18,\n",
       " 8107,\n",
       " 18,\n",
       " 9953,\n",
       " 3922,\n",
       " 21043,\n",
       " 15120,\n",
       " 46729,\n",
       " 96511,\n",
       " 26130,\n",
       " 17161,\n",
       " 22656,\n",
       " 44915,\n",
       " 45059,\n",
       " 9554,\n",
       " 15836,\n",
       " 27384,\n",
       " 54872,\n",
       " 25287,\n",
       " 6701,\n",
       " 249,\n",
       " 42052,\n",
       " 74318,\n",
       " 1811]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.encode(\"波形智能创立于2023年3月，是一家专注文本内容生成的AI大模型创业公司。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e7e1e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d9dacba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_string(\"波形智能创立于2023年3月，是一家专注文本内容生成的AI大模型创业公司.\",\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3ae0b5",
   "metadata": {},
   "source": [
    "#### Turn tokens into text with `encoding.decode()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50df1df6",
   "metadata": {},
   "source": [
    "`.decode()` converts a list of token integers to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61bf722d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'波形智能'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.decode([14888, 95, 83799, 45114, 118, 27327])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89e1eb3",
   "metadata": {},
   "source": [
    "#### Counting tokens for chat completions API calls\n",
    "\n",
    "ChatGPT models like `gpt-3.5-turbo` and `gpt-4` use tokens in the same way as older completions models, but because of their message-based formatting, it's more difficult to count how many tokens will be used by a conversation.\n",
    "\n",
    "Below is an example function for counting tokens for messages passed to `gpt-3.5-turbo` or `gpt-4`.\n",
    "\n",
    "Note that the exact way that tokens are counted from messages may change from model to model. Consider the counts from the function below an estimate, not a timeless guarantee.\n",
    "\n",
    "In particular, requests that use the optional functions input will consume extra tokens on top of the estimates calculated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "553a7ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\"):\n",
    "    \"\"\"Return the number of tokens used by a list of messages.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        print(\"Warning: model not found. Using cl100k_base encoding.\")\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if model in {\n",
    "        \"gpt-3.5-turbo-0613\",\n",
    "        \"gpt-3.5-turbo-16k-0613\",\n",
    "        \"gpt-4-0314\",\n",
    "        \"gpt-4-32k-0314\",\n",
    "        \"gpt-4-0613\",\n",
    "        \"gpt-4-32k-0613\",\n",
    "        }:\n",
    "        tokens_per_message = 3\n",
    "        tokens_per_name = 1\n",
    "    elif model == \"gpt-3.5-turbo-0301\":\n",
    "        tokens_per_message = 4  # every message follows <|start|>{role/name}\\n{content}<|end|>\\n\n",
    "        tokens_per_name = -1  # if there's a name, the role is omitted\n",
    "    elif \"gpt-3.5-turbo\" in model:\n",
    "        print(\"Warning: gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\")\n",
    "    elif \"gpt-4\" in model:\n",
    "        print(\"Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-4-0613\")\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"\"\"num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\"\n",
    "        )\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "    return num_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb97689",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bab09af",
   "metadata": {},
   "source": [
    "#### Async usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7aea4edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd09959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI(api_key=api_key)\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    chat_completion = await client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Say this is a test\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "    )\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b257cbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为什么牛排去参加派对？因为它想成为“菲力牛排”！哈哈哈哈哈。\n",
      "CompletionUsage(completion_tokens=37, prompt_tokens=11, total_tokens=48)\n",
      "在春风吹拂的季节里，\n",
      "花开如梦，浸染着世界的色彩。\n",
      "阳光温暖，润泽着大地，\n",
      "万物复苏，生机盎然。\n",
      "\n",
      "莺啼燕舞，歌唱着春天的旋律，\n",
      "细雨飘洒，轻柔如丝，滋润着心田。\n",
      "枝头新绿，柔嫩欲滴，\n",
      "清风拂过，扬起一片花瓣。\n",
      "\n",
      "此时此刻，心花怒放，\n",
      "感受春天的温暖，沐浴其光辉。\n",
      "让我们珍惜，这片刻的美好，\n",
      "在春风中，舞动自己的灵魂。\n",
      "CompletionUsage(completion_tokens=225, prompt_tokens=12, total_tokens=237)\n",
      "Sure, here's a sample code in Python that calculates the factorial of a given number:\n",
      "\n",
      "```python\n",
      "def factorial(n):\n",
      "    if n == 0:\n",
      "        return 1\n",
      "    else:\n",
      "        return n * factorial(n - 1)\n",
      "\n",
      "number = int(input(\"Enter a number: \"))\n",
      "result = factorial(number)\n",
      "print(f\"The factorial of {number} is {result}\")\n",
      "```\n",
      "\n",
      "You can run this code in a Python interpreter and enter a number to calculate its factorial.\n",
      "CompletionUsage(completion_tokens=97, prompt_tokens=11, total_tokens=108)\n"
     ]
    }
   ],
   "source": [
    "async def make_request(content: str, model=\"gpt-3.5-turbo\"):\n",
    "    chat_completion = await client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "    )\n",
    "    return chat_completion\n",
    "\n",
    "async def main():\n",
    "    # 使用 asyncio.gather 同时发送三个请求\n",
    "    responses = await asyncio.gather(\n",
    "        make_request(\"写一个笑话\"),\n",
    "        make_request(\"写一首诗\"),\n",
    "        make_request(\"写一段代码\"),\n",
    "    )\n",
    "\n",
    "    # 打印所有响应\n",
    "    for response in responses:\n",
    "        print(response.choices[0].message.content)\n",
    "        print(response.usage)\n",
    "\n",
    "# 运行主函数\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa097ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
